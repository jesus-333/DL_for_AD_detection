batch_size = 48
lr = 0.01
epochs = 2
optimizer_weight_decay = 0.01
device = "mps"
epoch_to_save_model = 10
path_to_save_model = "model_weights"
measure_metrics_during_training = true
print_var = true
seed = -1
use_weights_with_lower_validation_error = true

# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
# Wandb settings

wandb_training = false
project_name = "demnet_training_FL_kaggle"
model_artifact_name = "demnet_training_FL_kaggle"
log_freq = 1
name_training_run = "run_"
notes = ""
debug = true

# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 
# LR Scheduler settings

use_scheduler = true
[lr_scheduler_config]
name = 'ChainedScheduler'
[lr_scheduler_config.list_config_schedulers.config_1]
name = 'CosineAnnealingLR'
T_max = 9
eta_min = 1e-5
[lr_scheduler_config.list_config_schedulers.config_2]
name = 'ExponentialLR'
gamma = 0.92


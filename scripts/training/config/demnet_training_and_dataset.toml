[train_config]
batch_size = 128
lr = 0.01
epochs = 5
optimizer_weight_decay = 0.01
device = "mps"
epoch_to_save_model = 10
path_to_save_model = "model_weights"
measure_metrics_during_training = true
print_var = true
seed = -1
wandb_training = false
project_name = "demnet_training_ADNI"
model_artifact_name = "demnet_training_ADNI"
log_freq = 1
name_training_run = ""
notes = ""
debug = false
use_scheduler = true
# [train_config.lr_scheduler_config]
# name = 'CosineAnnealingLR'
# T_max = 20
# eta_min = 1e-5
# gamma = 0.96 
# step_size = 5
[train_config.lr_scheduler_config]
name = 'ChainedScheduler'
[train_config.lr_scheduler_config.list_config_schedulers.config_1]
name = 'CosineAnnealingLR'
T_max = 9
eta_min = 1e-5
[train_config.lr_scheduler_config.list_config_schedulers.config_2]
name = 'ExponentialLR'
gamma = 0.93

[dataset_config]
use_normalization = false
n_samples = 19200
# n_samples = 6400
merge_AD_class = 0
load_data_in_memory = true
percentage_train = 0.7
percentage_validation = 0.15
percentage_test = 0.15
grey_scale_image = true

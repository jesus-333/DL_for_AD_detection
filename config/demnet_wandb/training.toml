batch_size = 64
lr = 0.001
epochs = 40
optimizer_weight_decay = 0.01
device = "cpu"
epoch_to_save_model = -1
path_to_save_model = "model_weights"
measure_metrics_during_training = true
print_var = true
seed = -1
wandb_training = false
log_freq = 1
debug = false
use_scheduler = false
notes = ""

[lr_scheduler_config]
name = "ChainedScheduler"

[lr_scheduler_config.list_config_schedulers.config_1]
name = "CosineAnnealingLR"
T_max = 9
eta_min = 1e-5

[lr_scheduler_config.list_config_schedulers.config_2]
name = "ExponentialLR"
gamma = 0.93
